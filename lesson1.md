***

***

***

> # 备注

开场，大家好，我是高家华，很荣幸今天在这里和大家一起讨论python的性能分析

自我介绍：

- 来自腾讯反病毒实验室


- 12毕业加入腾讯


- 工作五年


- 一直从事客户端和后台的安全工作

## 课程介绍

python性能优化重不重要

在硬件越来越便宜，速度越来越快的今天，如果自己写一个python小程序，或者说在个人电脑上跑的一个一次性python任务，那么性能优化并不重要，一个小程序10s或者100s跑完，区别不大；一次性的数据处理任务，即使性能不好，也没有太多性能分析的价值。等你性能分析，性能优化一套做完，这个任务都已经做完了，以后可能再也不做这个任务了，优化也就没有意义了。

但是真实的工作场景中，越来越多的地方使用python，机器学习（人工智能）现在的技术风口啊，这里边python用的很多。Scikit-learn，TensorFlow ，还有最近也比较火的量化交易，python也用的很多。

举个我们团队的例子，我们有几百台服务器组成的分析集群来进行木马病毒分析，集群调度和分析结果处理我们都是用python实现的，里边有一些机器学习模型的应用，也是python的。我们每天处理上千万的分析任务，python的性能优化就显得很有意义了。


Python性能优化相关的课程会有三节

1. Python性能分析
2. Python性能优化的技巧及原理
3. Python性能优化实践

第一节主要讲怎么做性能分析，介绍一些性能分析的工具
第二节讲怎么做性能优化，怎么去写效率更高的python代码
第三节结合具体的例子讲性能优化实践
没有性能分析就无法进行性能优化，性能优化的技巧为解决实际问题服务，这三节课是个循序渐进的过程。
##背景知识
下边来说一下今天这节课适合的受众。整个这三堂课，属于python的初级偏中级的课程，首先需要写过一点python，没写过python直接听性能优化效果不会太好，对应不到已有知识点和技术点。大家也用担心，听懂这个课也不需要几万行python代码量那么夸张，python不像C++学习曲线那么陡峭，边写边学就可以。如果在写Python的过程中思考过一些性能问题，或者现在的学习当中就有python性能优化的需求，那就比较适合听这门课了。
那什么样的人不适合呢？刚才说过没写过python不适合，下边我展开这节课的目录，大家看下，如果都了解，也不是目标受众。
## 目录介绍
今晚的课程分成三个部分，运行时间分析，内存分析，可视化工具。运行时间这部分介绍了三种简单分析方法，shell 的time命令，python的time模块，python的timeit模块，还有两个能做详细分析的性能分析器。第二部分内存分析，讲了两个内存使用情况分析工具，其中memory_profiler比较宏观，侧重点在整体的内存占用大小。objgraph比较微观，能得到每个对象的增长情况。第三部分介绍两个可视化的工具。如果上边提到的这些东西，你都比较熟悉，就像我刚才说的，你也不适合这个课程。现在可以关了这个视频了，开两局王者荣耀去吧。

## 概述：
下边正式开始今天的课程



- 什么是性能分析：
  分析代码和它正在使用的资源之间有着怎样的关系。例如，性能分析可以告诉你一个指令或者说一段代码占用了多少CPU时间，告诉你整个程序消耗了多少内存，告诉你这个代码片段增加分配了多少内存。

  性能分析是一个很大的话题，我们今天要讨论的是python性能分析。

  ​



- 怎么做python性能分析 

  + 程序运行的速度如何
  + 时间瓶颈在哪里/内存瓶颈在哪里
  + 改进性能瓶颈

  ​

> #正文

#1. 运行时间分析
- 算法时间复杂度

  说到运行时间分析，很多人会联想到算法时间复杂度，课堂上学的老师教的对比两种算法哪个更高效靠的就是这个。
  ​

  看这个表格，里边列了常见的集中时间复杂度。

  O(1)   消耗时间固定，不随着已有数据规模而增加，不涉及到n的概念

  先说第三个线性时间，回头再说对数时间。查找无序列表的最小元素，得把所有元素遍历一遍，这就是O(n)。像二分查找，就不需要所有的遍历一遍，比较一次砍掉一半数据，数据量越大越能体现出比线性时间的优势。

  线性对数时间，快速排序的理想情况，每次选取的标杆能把当前无序 列表平均分成两块，O(nlogn)

  冒泡排序，所有数据遍历一次是线性时间，每次要找到最小的或者最大的还是线性时间，O(n**2)

  ​

  算法时间复杂度是对算法做分析的基础，但我们今天不靠理论分析，就看实际测量的值。

## 1.1 Shell 命令time

  今天介绍的第一个方法，也是最简单的方法，linux shell下的time命令。这个命令不仅仅用于python，可以直接测量一个shell命令的运行时间或者一个程序的运行时间，名字叫time但并不是用来显示和修改系统时间的。

  ​

  看下边这个图，ls 命令是linux下展示当前文件夹内容的命令。windows下如果要使用的话，要么是装虚拟机，要么通过是Cygwin这样的模拟环境，这里我推荐第二种。

  time命令直接测量ls命令的耗时，结果分三行，real是这个程序从开始到结束总共花了多少时间，user是cpu在用户态耗时，sys是cpu在内核态耗时。ls命令执行的比较快，下边我们换个执行的慢一点的。看这个python脚本，从0到9999做累加。time python 加脚本的名字，就能测量这个脚本的执行时间。这个脚本里边是累加操作，所以属于重计算的任务，再看下边这个脚本sleep 2s，这就不是重计算的任务，可以模拟一个重I/O的任务。

  ​

  结论：

1. time命令首先要关注的就是real这个时间，这是程序性能最直观的展示

2. 其次要关注user和sys加起来作为一个整体和real的关系，real 不等于user + sys，第二个脚本就是为了说明这个问题，当程序中有I/O执行，或者等待一个事件的时候，real就会大于user+sys。real 和 user + sys的值越接近，证明程序越重计算，反之说明程序更重IO。

3. 有没有real 小于user + sys的情况呢，系统是多核并且代码优化的好有可能出现这种情况的。但这个不是重点，重点是前边说的两个。

       ​
##1.2 Python自带模块time

因为是Python自带的模块，所以用起来非常简单，直接import进来就可以调用了。time模块的time函数返回的是一个绝对时间，1970早上8点0分0秒后经过的浮点秒数，asctime和localtime配合可以转成我们常见的时间格式。但是这里我们用这个模块来进行程序执行时间测量，所以asctime和localtime用不到。



一般情况进行时间测量任务，我们一开始会像下边这么写，两次计时取时间差。这么写确实简单，也足够灵活，两次测量之间加入Python代码和函数调用都很方便，但是当你的代码要分很多个小块，对每一个小块都去测量的时候，还按这么写就会比较麻烦，并且很不优雅。



一种比较流行的封装的方式，是timer.py这种写法。首先创建一个类，构造函数有个参数verbose，是个打印log的开关。然后有两个成员函数，__enter__和__exit__，enter这个函数进行第一次计时用start来存，exit这个函数进行第二次计时，并且做了一个减法计算，结果就是两次调用之间的时间间隔。



封装之后的使用在下边这个Python代码段中，首先把封装好的类import进来，第二行import的redis是一个nosql的数据库，挺热门的一个东西，这里不展开介绍了，如果你没听说就直接把它当成一个数据库就好。再下边一行代码，创建一个redis数据库，然后对数据存取分别使用我们封装的Timer进行操作计时。

这个结果我没贴，实际带大家操作下。（先启动redis server，然后再运行脚本）



顺便说一个time模块下的clock()函数，windows下推荐用time.clock代替time.time

## 1.3 python模块timeit

Python有一个自己封装好的timeit模块，很类似刚才我们自己封装起来的timer。

可以用timeit直接测一个Python语句的性能消耗，大家看我这里写的例子，就是直接测x = range(100)这句的性能消耗，看下边这个输出结果，0.6s是不是有些高啊。其实timeit默认就会循环1六个0，100万次。



大家可以去看下timeit的源码，在windows上用的是time.clock()，其他操作系统上用的是time.time()

(这里应该是20分钟，如果不足就展开下timeit的源码)



## 1.4 Python默认性能分析器cProfile

上边讲的三种方法都比较简单，适合做粗略统计，下面讲两个性能分析器，相对于前边提到的shell 命令，time模块，timeit模块，性能分析器的分析结果更深入，更详细。



cProfile自Python 2.5以来就是标准版Python解释器默认的性能分析器，主要功能是测量CPU运行时间，统计函数调用次数。虽然没有针对内存的分析，但仍是性能优化过程中一个重要的环节，绝大多数时候这个都能为我们的分析工作提供有力支持。



cProfile有两种使用方式，一种是在Python代码中使用，import cProfile模块进来，另一种是在Python脚本启动的命令行中增加额外参数，针对整个脚本进行性能分析。

- 先说第一种情况，代码如下所示，运行结果比较长，没在我的文档中贴，我实际演示一下吧。

> ## 演示

- 下边说下在命令行中的使用，使用的Python脚本就是刚才在讲time模块的时候Redis的例子。

  直接运行一个脚本的使用时Python空格脚本路径，如果要使用cProfile的话就在中间增加 -m cProfile，注意cProfile要严格区分大小写的。

  ​

  第二行命令字 -o 这个参数后边跟的是输出的分析日志，这个分析日志是不能直接用记事本打开读的，不是把刚刚在命令行中直接打印出来的东西存到文本文件中，-o 命令生成的log要用专门的分析工具去打开，这个点我们在第三部分的可视化工具当中讲。如果单纯地想把命令行展示的东西存成文本文件，直接使用重定向符就好了。

  ​


##1.5 第三方性能分析器line_profiler
核心就在于line这个单词，这个性能分析器和cProfile不同。它可以帮助你一行一行地分析函数性能。cProfile主要关注函数的性能，如果你的程序性能瓶颈出现在某一行python代码中，line_profiler显得非常恰当。

cProfile是更深入的，每一行的代码的内部调用都被记录下，line_profiler只精确到行。


由于这是第三方的，需要我们安装下这个模块，python中安全第三方模块比较好用的是pip方式。

这个模块有部分是需要在本地系统中编译的，所以需要vs编译工具，如果你操作系统装了vs2008应该可以直接安装成功，要不然很可能会有个错误提示。

> Microsoft Visual C++ 9.0 is required 
> 如果你的电脑中装了比2008版本更高的vs，那么直接增加一个环境变量。
> 如果没有的话，去下边这个网址下载编译支持包，一路下一步，然后再用pip安装 。

使用方法，line_profiler的作者建议使用其中的kernprof工具，下边的介绍也是基于kernprof的。

首先修改源代码，在待测试函数的前边加上一行，@profile，对Python比较了解的人可能会知道，这个叫做装饰器，大概意思就是在函数外边再包一层，不知道也没关系，这不是今天必须要掌握的知识点。



往下看用来做测试的代码，这代码就是从0到9999逐个累加。在源代码上增加@profile这一行，保存，命令行启动 kernprof -l -v 两个参数，后边接待测试的脚本。-l 的意思是通知kerprof去分析被装饰的函数，-v的意思是执行完毕显示详细信息。



看下边的效果图，把待测函数的每一都列出来了，

- Line #：表示文件中的行号。


- Hits：性能分析时一行代码的执行次数。


- Time：一行代码执行的总时间，由计时器的单位决定。在分析结果的最开始有一行Timer unit

> **我这个图截取的有一点问题啊，少了这一行，我再运行一次**

该数值就是转换成秒的计时单位（要计算总时间，需要用Time数值乘以计时单位）。不同系统的计时单位可能不同。

- Per hit：执行一行代码的平均消耗时间，依然由系统的计时单位决定。


- % Time：执行一行代码的时间消耗占程序总消耗时间的比例。


# 内存管理

- 引用计数
- 标记清除
- 分代回收

